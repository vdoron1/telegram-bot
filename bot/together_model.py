import os
import requests
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º API-–∫–ª—é—á
load_dotenv()
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")

# –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å (—Å–º. https://api.together.xyz/models)
MODEL = "meta-llama/Llama-3.3-70B-Instruct-Turbo"

HEADERS = {
    "Authorization": f"Bearer {TOGETHER_API_KEY}",
    "Content-Type": "application/json"
}

def get_together_response(prompt: str, max_tokens: int = 100) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Together AI API –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"""
    url = "https://api.together.xyz/v1/chat/completions"

    payload = {
        "model": MODEL,
        "prompt": prompt,
        "max_tokens": max_tokens,
        "temperature": 0.7,
        "top_p": 0.9
    }

    try:
        response = requests.post(url, headers=HEADERS, json=payload)
        response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫–∏ API
        data = response.json()

        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç API (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
        print("üîπ –û—Ç–≤–µ—Ç API:", data)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ "choices" –≤ –æ—Ç–≤–µ—Ç–µ
        if "choices" in data and len(data["choices"]) > 0:
            if "text" in data["choices"][0]:  # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç API
                return data["choices"][0]["text"].strip()
            elif "message" in data["choices"][0]:  # –î—Ä—É–≥–æ–π –≤–∞—Ä–∏–∞–Ω—Ç API
                return data["choices"][0]["message"]["content"].strip()
            elif "output" in data:  # –í–æ–∑–º–æ–∂–Ω–æ, –æ—Ç–≤–µ—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç –∑–¥–µ—Å—å
                return data["output"].strip()
            else:
                return "‚ö†Ô∏è –û—à–∏–±–∫–∞: API –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç."
        else:
            return "‚ö†Ô∏è –û—à–∏–±–∫–∞: API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç."

    except requests.exceptions.RequestException as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API: {str(e)}"